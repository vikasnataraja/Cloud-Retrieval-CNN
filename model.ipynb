{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/viha4393/anaconda36/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, UpSampling2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.layers import BatchNormalization, Activation, Dropout\n",
    "from keras.layers import ZeroPadding2D, Lambda\n",
    "\n",
    "# might be keras.layers.merge import Add Concatenate\n",
    "from keras.layers import Concatenate, Add\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def BatchNorm():\n",
    "    return BatchNormalization(momentum=0.95, epsilon=1e-5)\n",
    "\n",
    "\n",
    "def upsample_bilinear(in_tensor, new_size):\n",
    "    resized_height, resized_width = new_size\n",
    "    return tf.image.resize(images=in_tensor,size=[resized_height,resized_width],\n",
    "                           method=ResizeMethodV1.BILINEAR,\n",
    "                           align_corners=True)\n",
    "\n",
    "def spp_block(prev_layer, pool_size, feature_map_shape):\n",
    "\n",
    "    #kernel = [(1,1),(2,2),(4,4),(8,8)]\n",
    "    #strides = [(1,1),(2,2),(4,4),(8,8)]\n",
    "    pool_size_tuple = (pool_size, pool_size)\n",
    "    prev_layer = AveragePooling2D(pool_size=pool_size_tuple)\n",
    "    prev_layer = Conv2D(128, (1, 1), strides=(1, 1),\n",
    "                        use_bias=False)(prev_layer)\n",
    "    prev_layer = BatchNorm(name=names[1])(prev_layer)\n",
    "    prev_layer = Activation('relu')(prev_layer)\n",
    "    \n",
    "    # prev_layer = Lambda(Interp, arguments={\n",
    "    #                    'shape': feature_map_shape})(prev_layer)\n",
    "    \n",
    "    # upsampling\n",
    "    prev_layer = upsample_bilinear(prev_layer,feature_map_shape)\n",
    "    #prev_layer = UpSampling2D(size=(2, 2),\n",
    "    #                          interpolation='bilinear')\n",
    "\n",
    "    return prev_layer\n",
    "\n",
    "def common_skip(prev, num_filters, atrous_rate, \n",
    "                kernel_size, stride_tuple, name):\n",
    "    \"\"\"\n",
    "    The common ResNet block shared by the identity block\n",
    "    and the convolutional block. Both of those blocks share\n",
    "    this common functionality.\n",
    "    \"\"\"\n",
    "\n",
    "    prev = BatchNorm()(prev)\n",
    "    prev = Activation('relu')(prev)\n",
    "    # prev = ZeroPadding2D(padding=(pad, pad))(prev)\n",
    "    \n",
    "    \"\"\"Syntax:\n",
    "    keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), \n",
    "                    padding='valid', data_format=None, dilation_rate=(1, 1),\n",
    "                    activation=None, use_bias=True)\n",
    "    \"\"\"\n",
    "    prev = Conv2D(num_filters, kernel_size=kernel_size, \n",
    "                  strides=stride_tuple, dilation_rate=atrous_rate,\n",
    "                  use_bias=False)(prev)\n",
    "    if name==\"halve_feature_map\":\n",
    "        prev = MaxPooling2D(pool_size=(2,2),padding='valid')\n",
    "\n",
    "    prev = BatchNorm()(prev)\n",
    "    prev = Activation('relu')(prev)\n",
    "    # dropout rate is 10%\n",
    "    prev = Dropout(rate=0.1)\n",
    "    prev = Conv2D(num_filters, kernel_size=kernel_size, \n",
    "                  strides=stride_tuple, dilation_rate=atrous_rate,\n",
    "                  use_bias=False)(prev)\n",
    "    \n",
    "    # I think this should be followed by BatchNorm and an activation\n",
    "    return prev\n",
    "\n",
    "def convolution_branch(name, num_filters, kernel_size, prev):\n",
    "\n",
    "    prev = Conv2D(num_filters, kernel_size=(1, 1), strides=(2, 2),\n",
    "                      use_bias=False)(prev)\n",
    "    \n",
    "    if name=='halve_feature_map':\n",
    "        # halve the size of feature map by using valid padding, 2x2 pooling\n",
    "        prev = MaxPooling2D(pool_size=(2,2),padding='valid')\n",
    "\n",
    "    prev = BatchNorm()(prev)\n",
    "    return prev\n",
    "\n",
    "\n",
    "def empty_branch(prev):\n",
    "    return prev\n",
    "\n",
    "def convolutional_resnet_block(prev_layer, num_filters, name, kernel_size,\n",
    "                               stride_tuple,atrous_rate=1):\n",
    "   \n",
    "    prev_layer = Activation('relu')(prev_layer)\n",
    "    block_1 = common_skip(prev_layer, num_filters, name, kernel_size=kernel_size, \n",
    "                          stride_tuple=stride_tuple,\n",
    "                          atrous_rate=atrous_rate)\n",
    "\n",
    "    block_2 = convolution_branch(name, num_filters=num_filters,\n",
    "                                 kernel_size=kernel_size, \n",
    "                                 prev_layer=prev_layer)\n",
    "    added = Add()([block_1, block_2])\n",
    "    \n",
    "    return added\n",
    "    \n",
    "\n",
    "def identity_resnet_block(prev_layer, num_filters, name, kernel_size,\n",
    "                          stride_tuple, atrous_rate=1):\n",
    "    \n",
    "    prev_layer = Activation('relu')(prev_layer)\n",
    "\n",
    "    block_1 = common_skip(prev_layer, num_filters, name, kernel_size=kernel_size, \n",
    "                          stride_tuple=stride_tuple,\n",
    "                          atrous_rate=atrous_rate)\n",
    "    \n",
    "    block_2 = empty_branch(prev_layer)\n",
    "    \n",
    "    added = Add()([block_1, block_2])\n",
    "    \n",
    "    return added\n",
    "\n",
    "\n",
    "def ResNet(input_layer):\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), strides=(1, 1), padding='same',\n",
    "                  use_bias=False)(input_layer)\n",
    "    \n",
    "    x = identity_resnet_block(x, num_filters=16, kernel_size=(3,3),\n",
    "                              stride_tuple=(1,1), name=\"identity\",\n",
    "                              atrous_rate=1)\n",
    "    \n",
    "    x = convolutional_resnet_block(x, num_filters=32, kernel_size=(3,3),\n",
    "                                   stride_tuple=(1,1), name=\"halve_feature_map\",\n",
    "                                   atrous_rate=1)\n",
    "    \n",
    "    x = convolutional_resnet_block(x, num_filters=64, kernel_size=(3,3),\n",
    "                                   stride_tuple=(1,1), name=\"halve_feature_map\", \n",
    "                                   atrous_rate=1)\n",
    "    \n",
    "    x = identity_resnet_block(x, num_filters=64, kernel_size=(3,3),\n",
    "                              stride_tuple=(1,1), name=\"identity\",\n",
    "                              atrous_rate=1)\n",
    "    \n",
    "    x = convolutional_resnet_block(x, num_filters=128, kernel_size=(3,3),\n",
    "                                   stride_tuple=(1,1), name=\"halve_feature_map\", \n",
    "                                   atrous_rate=1)\n",
    "    \n",
    "    x = identity_resnet_block(x, num_filters=128, kernel_size=(3,3),\n",
    "                              stride_tuple=(1,1), name=\"identity\",\n",
    "                              atrous_rate=1)\n",
    "    \n",
    "    \"\"\" dilated/atrous convolutional ResNet block starts here\"\"\"\n",
    "    \n",
    "    x = convolutional_resnet_block(x, num_filters=256, kernel_size=(3,3),\n",
    "                                   stride_tuple=(1,1), name=\"full_feature_map\", \n",
    "                                   atrous_rate=2)\n",
    "    \n",
    "    x = identity_resnet_block(x, num_filters=256, kernel_size=(3,3),\n",
    "                              stride_tuple=(1,1), name=\"identity\",\n",
    "                              atrous_rate=2)\n",
    "    \n",
    "    x = convolutional_resnet_block(x, num_filters=512, kernel_size=(3,3),\n",
    "                                   stride_tuple=(1,1), name=\"full_feature_map\", \n",
    "                                   atrous_rate=4)\n",
    "    \n",
    "    x = identity_resnet_block(x, num_filters=512, kernel_size=(3,3),\n",
    "                              stride_tuple=(1,1), name=\"identity\",\n",
    "                              atrous_rate=4)\n",
    "    #Syntax:\n",
    "    #keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), \n",
    "    #                padding='valid', data_format=None, dilation_rate=(1, 1),\n",
    "    #                activation=None, use_bias=True)\n",
    "    \n",
    "    x = Conv2D(filters=512,kernel_size=(3,3),\n",
    "               strides=(1,1), padding='valid',dilation_rate=2)(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=512,kernel_size=(3,3),\n",
    "               strides=(1,1), padding='valid',dilation_rate=2)(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    \"\"\"End of dilated convolution block\"\"\"\n",
    "    \n",
    "    x = Conv2D(filters=512,kernel_size=(3,3),\n",
    "               strides=(1,1), padding='valid',dilation_rate=1)(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=512,kernel_size=(3,3),\n",
    "               strides=(1,1), padding='valid',dilation_rate=1)(x)\n",
    "    x = BatchNorm()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\"\"\"Spatial Pyramid Pooling\"\"\"\n",
    "def build_pyramid_pooling_module(resnet_last):\n",
    "    \"\"\"Build the Pyramid Pooling Module.\"\"\"\n",
    "    \n",
    "    # feature map size to be used for interpolation\n",
    "    feature_map_size = (16,16) # (height, width) not (width, height)\n",
    "    pool_sizes = [1,2,4,8]\n",
    "\n",
    "    pool_block1 = spp_block(resnet_last, pool_sizes[0], feature_map_size)\n",
    "    pool_block2 = spp_block(resnet_last, pool_sizes[1], feature_map_size)\n",
    "    pool_block4 = spp_block(resnet_last, pool_sizes[2], feature_map_size)\n",
    "    pool_block8 = spp_block(resnet_last, pool_sizes[3], feature_map_size)\n",
    "\n",
    "    # concat all these layers. resulted\n",
    "    # shape=(1,feature_map_size_x,feature_map_size_y,4096)\n",
    "    concat = Concatenate()([resnet_last,\n",
    "                            pool_block8,\n",
    "                            pool_block4,\n",
    "                            pool_block2,\n",
    "                            pool_block1])\n",
    "    return concat    \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Deconvolution layer comes after concatenation of SPP layers\n",
    "https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/layers/Conv2DTranspose\n",
    "From the paper:\n",
    "\"Finally, multi-scale features are fused to obtain an image with \n",
    "the same size as the input image by the transposed convolution\"\n",
    "\"\"\"\n",
    "def add_deconvolution_layer(concat_layer):\n",
    "    deconv_layer = Conv2DTranspose(filters=1,kernel_size=(16,16))\n",
    "    return deconv_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
